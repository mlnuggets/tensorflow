{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "How to build artificial neural networks with Keras and TensorFlow.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## How to build artificial neural networks with Keras and TensorFlow\n",
    "Dataset is obtained from [Kaggle](https://www.kaggle.com/datasets/teejmahal20/airline-passenger-satisfaction?select=train.csv).\n",
    "\n",
    "Click the image below to read the post online.\n",
    "\n",
    "<a target=\"_blank\" href=\"https://www.machinelearningnuggets.com/how-to-build-artificial-neural-networks-with-keras-and-tensorflow\n",
    "\"><img src=\"https://digitalpress.fra1.cdn.digitaloceanspaces.com/mhujhsj/2022/07/logo.png\" alt=\"Open in ML Nuggets\"></a>"
   ],
   "metadata": {
    "id": "M9K_OteeQHCz"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TensorFlow basics"
   ],
   "metadata": {
    "id": "x_f3AwzxsS_t"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tensors"
   ],
   "metadata": {
    "id": "WEqssMtXsVjV"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "TensorFlow operates on multidimensional arrays or tensors represented as tf.Tensor objects."
   ],
   "metadata": {
    "id": "nP3uG5s2uXoU"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RjkEqvZMzO88"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "x = tf.constant([[7., 8., 9.],\n",
    "                 [10., 11., 12.]])\n",
    "\n",
    "print(x)\n",
    "print(x.shape)\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "x[0]"
   ],
   "metadata": {
    "id": "PQwoCrAbwSUr"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "x[1:4]"
   ],
   "metadata": {
    "id": "C-H5kwfHwXmt"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "x**2"
   ],
   "metadata": {
    "id": "6Sd-jaC5upRf"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "x @ tf.transpose(x)"
   ],
   "metadata": {
    "id": "lZwF1hq6uvXl"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tf.concat([x, x, x], axis=0)"
   ],
   "metadata": {
    "id": "fSB1UvYBu0wY"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "np.array(x)"
   ],
   "metadata": {
    "id": "5kLWC-pyv1aE"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "x.numpy()"
   ],
   "metadata": {
    "id": "UFlTsBhQv5Np"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "x.shape.as_list()"
   ],
   "metadata": {
    "id": "DD7_2dCqwi64"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tf.nn.softmax(x, axis=-1)"
   ],
   "metadata": {
    "id": "oBySZ4SAu4S8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tf.reduce_sum(x)"
   ],
   "metadata": {
    "id": "_okhxs7fu66M"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "if tf.config.list_physical_devices('GPU'):\n",
    "  print(\"TensorFlow **IS** using the GPU\")\n",
    "else:\n",
    "  print(\"TensorFlow **IS NOT** using the GPU\")"
   ],
   "metadata": {
    "id": "nHM5TD_CvEpW"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# There can be an arbitrary number of\n",
    "# axes (sometimes called \"dimensions\")\n",
    "rank_3_tensor = tf.constant([\n",
    "  [[0, 1, 2, 3, 4],\n",
    "   [5, 6, 7, 8, 9]],\n",
    "  [[10, 11, 12, 13, 14],\n",
    "   [15, 16, 17, 18, 19]],\n",
    "  [[20, 21, 22, 23, 24],\n",
    "   [25, 26, 27, 28, 29]],])\n",
    "\n",
    "print(rank_3_tensor)"
   ],
   "metadata": {
    "id": "d9ZDGN_HvEkF"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# If you have three string tensors of different lengths, this is OK.\n",
    "tensor_of_strings = tf.constant([\"Gray wolf\",\n",
    "                                 \"Quick brown fox\",\n",
    "                                 \"Lazy dog\"])\n",
    "# Note that the shape is (3,). The string length is not included.\n",
    "print(tensor_of_strings)"
   ],
   "metadata": {
    "id": "cTarA2rEvEbQ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "ragged_list = [\n",
    "    [0, 1, 2, 3],\n",
    "    [4, 5],\n",
    "    [6, 7, 8],\n",
    "    [9]]"
   ],
   "metadata": {
    "id": "lCTXARTbxCwb"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "try:\n",
    "  tensor = tf.constant(ragged_list)\n",
    "except Exception as e:\n",
    "  print(f\"{type(e).__name__}: {e}\")"
   ],
   "metadata": {
    "id": "XREN1fIrxGMD"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "ragged_tensor = tf.ragged.constant(ragged_list)\n",
    "print(ragged_tensor)"
   ],
   "metadata": {
    "id": "CARu6VVDxGJl"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(ragged_tensor.shape)"
   ],
   "metadata": {
    "id": "dFCczUjFxGG_"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Sparse tensors store values by index in a memory-efficient manner\n",
    "sparse_tensor = tf.sparse.SparseTensor(indices=[[0, 0], [1, 2]],\n",
    "                                       values=[1, 2],\n",
    "                                       dense_shape=[3, 4])\n",
    "print(sparse_tensor, \"\\n\")\n",
    "\n",
    "# You can convert sparse tensors to dense\n",
    "print(tf.sparse.to_dense(sparse_tensor))"
   ],
   "metadata": {
    "id": "-TZOh6FqxTNh"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Variables"
   ],
   "metadata": {
    "id": "f7tbWymisYTl"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# Uncomment to see where your variables get placed (see below)\n",
    "tf.debugging.set_log_device_placement(True)"
   ],
   "metadata": {
    "id": "zGNlomKmsaly"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "my_tensor = tf.constant([[8.0, 8.0], [6.0, 5.0]])\n",
    "my_variable = tf.Variable(my_tensor)\n",
    "\n",
    "# Variables can be all kinds of types, just like tensors\n",
    "bool_variable = tf.Variable([True, False, False, True])\n",
    "complex_variable = tf.Variable([8 + 4j, 8 + 1j])"
   ],
   "metadata": {
    "id": "4DM_HvUtxw1c"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "my_variable"
   ],
   "metadata": {
    "id": "KiaG4wHZxwvM"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"Shape: \", my_variable.shape)\n",
    "print(\"DType: \", my_variable.dtype)\n",
    "print(\"As NumPy: \", my_variable.numpy())"
   ],
   "metadata": {
    "id": "MIQXa-eBxwsU"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"A variable:\", my_variable)\n",
    "print(\"\\nViewed as a tensor:\", tf.convert_to_tensor(my_variable))\n",
    "print(\"\\nIndex of highest value:\", tf.math.argmin(my_variable))\n",
    "\n",
    "# This creates a new tensor; it does not reshape the variable.\n",
    "print(\"\\nCopying and reshaping: \", tf.reshape(my_variable, [1,4]))"
   ],
   "metadata": {
    "id": "DJZBmqMxxwlV"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "a = tf.Variable([2.0, 3.0])\n",
    "# This will keep the same dtype, float32\n",
    "a.assign([1, 2]) \n",
    "# Not allowed as it resizes the variable: \n",
    "try:\n",
    "  a.assign([1.0, 2.0, 3.0])\n",
    "except Exception as e:\n",
    "  print(f\"{type(e).__name__}: {e}\")"
   ],
   "metadata": {
    "id": "oFSr16-WyE1b"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "a = tf.Variable([2.0, 3.0])\n",
    "# Create b based on the value of a\n",
    "b = tf.Variable(a)\n",
    "a.assign([5, 6])\n",
    "\n",
    "# a and b are different\n",
    "print(a.numpy())\n",
    "print(b.numpy())\n",
    "\n",
    "# There are other versions of assign\n",
    "print(a.assign_add([2,3]).numpy())  # [7. 9.]\n",
    "print(a.assign_sub([7,9]).numpy())  # [0. 0.]"
   ],
   "metadata": {
    "id": "cF0XGN-1yEyS"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Create a and b; they will have the same name but will be backed by\n",
    "# different tensors.\n",
    "a = tf.Variable(my_tensor, name=\"ml nuggets\")\n",
    "# A new variable with the same name, but different value\n",
    "# Note that the scalar add is broadcast\n",
    "b = tf.Variable(my_tensor + 1, name=\"ml nuggets\")\n",
    "\n",
    "# These are elementwise-unequal, despite having the same name\n",
    "print(a == b)"
   ],
   "metadata": {
    "id": "gXlQzKJQyEuX"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "step_counter = tf.Variable(1, trainable=False)"
   ],
   "metadata": {
    "id": "9eT1gocwye-X"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "with tf.device('CPU:0'):\n",
    "\n",
    "  # Create some tensors\n",
    "  a = tf.Variable([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "  b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "  c = tf.matmul(a, b)\n",
    "\n",
    "print(c)"
   ],
   "metadata": {
    "id": "GJH-a0ekylde"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "with tf.device('CPU:0'):\n",
    "  a = tf.Variable([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "  b = tf.Variable([[1.0, 2.0, 3.0]])\n",
    "\n",
    "with tf.device('GPU:0'):\n",
    "  # Element-wise multiply\n",
    "  k = a * b\n",
    "\n",
    "print(k)"
   ],
   "metadata": {
    "id": "4y4DjnbPylbo"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Automatic differentiation"
   ],
   "metadata": {
    "id": "KZMrxtUxsboG"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "x = tf.Variable(47.0)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "  y = x**2"
   ],
   "metadata": {
    "id": "KrX6C6NJy2xy"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# dy = 2x * dx\n",
    "dy_dx = tape.gradient(y, x)\n",
    "dy_dx.numpy()"
   ],
   "metadata": {
    "id": "WO0bat11y2vt"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "w = tf.Variable(tf.random.normal((3, 2)), name='w')\n",
    "b = tf.Variable(tf.zeros(2, dtype=tf.float32), name='b')\n",
    "x = [[1., 2., 3.]]\n",
    "\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "  y = x @ w + b\n",
    "  loss = tf.reduce_mean(y**2)"
   ],
   "metadata": {
    "id": "l-xYA5P4y2t7"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "[dl_dw, dl_db] = tape.gradient(loss, [w, b])"
   ],
   "metadata": {
    "id": "o1USL2K-y2rw"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(w.shape)\n",
    "print(dl_dw.shape)"
   ],
   "metadata": {
    "id": "_J-rZpAby2ph"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "my_vars = {\n",
    "    'w': w,\n",
    "    'b': b\n",
    "}\n",
    "\n",
    "grad = tape.gradient(loss, my_vars)\n",
    "grad['b']"
   ],
   "metadata": {
    "id": "M1nCxoB1zsYl"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "layer = tf.keras.layers.Dense(2, activation='relu')\n",
    "x = tf.constant([[1., 2., 3.]])\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "  # Forward pass\n",
    "  y = layer(x)\n",
    "  loss = tf.reduce_mean(y**2)\n",
    "\n",
    "# Calculate gradients with respect to every trainable variable\n",
    "grad = tape.gradient(loss, layer.trainable_variables)"
   ],
   "metadata": {
    "id": "tYOlioCZzsWx"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for var, g in zip(layer.trainable_variables, grad):\n",
    "  print(f'{var.name}, shape: {g.shape}')"
   ],
   "metadata": {
    "id": "-0Dt8UGPzsUZ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Graphs & functions"
   ],
   "metadata": {
    "id": "ylCPR0k1seAd"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import timeit\n",
    "from datetime import datetime"
   ],
   "metadata": {
    "id": "c-oXT3x1sgLI"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Define a Python function.\n",
    "def a_regular_function(x, y, b):\n",
    "  x = tf.matmul(x, y)\n",
    "  x = x + b\n",
    "  return x\n",
    "\n",
    "# `a_function_that_uses_a_graph` is a TensorFlow `Function`.\n",
    "a_function_that_uses_a_graph = tf.function(a_regular_function)\n",
    "\n",
    "# Make some tensors.\n",
    "x1 = tf.constant([[1.0, 2.0]])\n",
    "y1 = tf.constant([[2.0], [3.0]])\n",
    "b1 = tf.constant(4.0)\n",
    "\n",
    "orig_value = a_regular_function(x1, y1, b1).numpy()\n",
    "# Call a `Function` like a Python function.\n",
    "tf_function_value = a_function_that_uses_a_graph(x1, y1, b1).numpy()\n",
    "assert(orig_value == tf_function_value)"
   ],
   "metadata": {
    "id": "8zaJFR4u2Kdm"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def inner_function(x, y, b):\n",
    "  x = tf.matmul(x, y)\n",
    "  x = x + b\n",
    "  return x\n",
    "\n",
    "# Use the decorator to make `outer_function` a `Function`.\n",
    "@tf.function\n",
    "def outer_function(x):\n",
    "  y = tf.constant([[2.0], [3.0]])\n",
    "  b = tf.constant(4.0)\n",
    "\n",
    "  return inner_function(x, y, b)\n",
    "\n",
    "# Note that the callable will create a graph that\n",
    "# includes `inner_function` as well as `outer_function`.\n",
    "outer_function(tf.constant([[1.0, 2.0]])).numpy()"
   ],
   "metadata": {
    "id": "rLBFQQSZ2Kbk"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def simple_relu(x):\n",
    "  if tf.greater(x, 0):\n",
    "    return x\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "# `tf_simple_relu` is a TensorFlow `Function` that wraps `simple_relu`.\n",
    "tf_simple_relu = tf.function(simple_relu)\n",
    "\n",
    "print(\"First branch, with graph:\", tf_simple_relu(tf.constant(1)).numpy())\n",
    "print(\"Second branch, with graph:\", tf_simple_relu(tf.constant(-1)).numpy())"
   ],
   "metadata": {
    "id": "S0A3qa5u2KZc"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# This is the graph-generating output of AutoGraph.\n",
    "print(tf.autograph.to_code(simple_relu))"
   ],
   "metadata": {
    "id": "T-yTlHen2kR7"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# This is the graph itself.\n",
    "print(tf_simple_relu.get_concrete_function(tf.constant(1)).graph.as_graph_def())"
   ],
   "metadata": {
    "id": "5aObseBH2kOm"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Modules, layers, and models"
   ],
   "metadata": {
    "id": "uISfOdHcsgvd"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "from datetime import datetime\n",
    "\n",
    "%load_ext tensorboard"
   ],
   "metadata": {
    "id": "3dAVBgjrskSn"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class SimpleModule(tf.Module):\n",
    "  def __init__(self, name=None):\n",
    "    super().__init__(name=name)\n",
    "    self.a_variable = tf.Variable(5.0, name=\"train_me\")\n",
    "    self.non_trainable_variable = tf.Variable(5.0, trainable=False, name=\"do_not_train_me\")\n",
    "  def __call__(self, x):\n",
    "    return self.a_variable * x + self.non_trainable_variable\n",
    "\n",
    "simple_module = SimpleModule(name=\"simple\")\n",
    "\n",
    "simple_module(tf.constant(5.0))"
   ],
   "metadata": {
    "id": "8TRW0wo76NuC"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# All trainable variables\n",
    "print(\"trainable variables:\", simple_module.trainable_variables)\n",
    "# Every variable\n",
    "print(\"all variables:\", simple_module.variables)"
   ],
   "metadata": {
    "id": "n8CRbAUa6Noa"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class Dense(tf.Module):\n",
    "  def __init__(self, in_features, out_features, name=None):\n",
    "    super().__init__(name=name)\n",
    "    self.w = tf.Variable(\n",
    "      tf.random.normal([in_features, out_features]), name='w')\n",
    "    self.b = tf.Variable(tf.zeros([out_features]), name='b')\n",
    "  def __call__(self, x):\n",
    "    y = tf.matmul(x, self.w) + self.b\n",
    "    return tf.nn.relu(y)"
   ],
   "metadata": {
    "id": "TBEzCxqB6Nmz"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class SequentialModule(tf.Module):\n",
    "  def __init__(self, name=None):\n",
    "    super().__init__(name=name)\n",
    "\n",
    "    self.dense_1 = Dense(in_features=3, out_features=3)\n",
    "    self.dense_2 = Dense(in_features=3, out_features=2)\n",
    "\n",
    "  def __call__(self, x):\n",
    "    x = self.dense_1(x)\n",
    "    return self.dense_2(x)\n",
    "\n",
    "# You have made a model!\n",
    "my_model = SequentialModule(name=\"the_model\")\n",
    "\n",
    "# Call it, with random results\n",
    "print(\"Model results:\", my_model(tf.constant([[2.0, 2.0, 2.0]])))"
   ],
   "metadata": {
    "id": "iWMuDFaS62L8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class MySequentialModule(tf.Module):\n",
    "  def __init__(self, name=None):\n",
    "    super().__init__(name=name)\n",
    "\n",
    "    self.dense_1 = Dense(in_features=3, out_features=3)\n",
    "    self.dense_2 = Dense(in_features=3, out_features=2)\n",
    "\n",
    "  @tf.function\n",
    "  def __call__(self, x):\n",
    "    x = self.dense_1(x)\n",
    "    return self.dense_2(x)\n",
    "\n",
    "# You have made a model with a graph!\n",
    "my_model = MySequentialModule(name=\"the_model\")"
   ],
   "metadata": {
    "id": "AG7VOzNe7QGB"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Set up logging.\n",
    "stamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "logdir = \"logs/func/%s\" % stamp\n",
    "writer = tf.summary.create_file_writer(logdir)\n",
    "\n",
    "# Create a new model to get a fresh trace\n",
    "# Otherwise the summary will not see the graph.\n",
    "new_model = MySequentialModule()\n",
    "\n",
    "# Bracket the function call with\n",
    "# tf.summary.trace_on() and tf.summary.trace_export().\n",
    "tf.summary.trace_on(graph=True)\n",
    "tf.profiler.experimental.start(logdir)\n",
    "# Call only one tf.function when tracing.\n",
    "z = print(new_model(tf.constant([[2.0, 2.0, 2.0]])))\n",
    "with writer.as_default():\n",
    "  tf.summary.trace_export(\n",
    "      name=\"my_func_trace\",\n",
    "      step=0,\n",
    "      profiler_outdir=logdir)"
   ],
   "metadata": {
    "id": "izR_N-qe62Jk"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%tensorboard --logdir logs/func"
   ],
   "metadata": {
    "id": "YVNZCYFp62HQ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training loops"
   ],
   "metadata": {
    "id": "j4yjmDfRsmBu"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
   ],
   "metadata": {
    "id": "DLUsd13ksnEH"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# The actual line\n",
    "TRUE_W = 3.0\n",
    "TRUE_B = 2.0\n",
    "\n",
    "NUM_EXAMPLES = 201\n",
    "\n",
    "# A vector of random x values\n",
    "x = tf.linspace(-2,2, NUM_EXAMPLES)\n",
    "x = tf.cast(x, tf.float32)\n",
    "\n",
    "def f(x):\n",
    "  return x * TRUE_W + TRUE_B\n",
    "\n",
    "# Generate some noise\n",
    "noise = tf.random.normal(shape=[NUM_EXAMPLES])\n",
    "\n",
    "# Calculate y\n",
    "y = f(x) + noise"
   ],
   "metadata": {
    "id": "GB90nMzu8-Ko"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Plot all the data\n",
    "plt.plot(x, y, '.')\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "z_-DTMy58-IC"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class MyModel(tf.Module):\n",
    "  def __init__(self, **kwargs):\n",
    "    super().__init__(**kwargs)\n",
    "    # Initialize the weights to `5.0` and the bias to `0.0`\n",
    "    # In practice, these should be randomly initialized\n",
    "    self.w = tf.Variable(5.0)\n",
    "    self.b = tf.Variable(0.0)\n",
    "\n",
    "  def __call__(self, x):\n",
    "    return self.w * x + self.b\n",
    "\n",
    "model = MyModel()\n",
    "\n",
    "# List the variables tf.modules's built-in variable aggregation.\n",
    "print(\"Variables:\", model.variables)\n",
    "\n",
    "# Verify the model works\n",
    "assert model(3.0).numpy() == 15.0"
   ],
   "metadata": {
    "id": "EyjHZiEV8-D3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# This computes a single loss value for an entire batch\n",
    "def loss(target_y, predicted_y):\n",
    "  return tf.reduce_mean(tf.square(target_y - predicted_y))"
   ],
   "metadata": {
    "id": "JcubLvmI9FqW"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plt.plot(x, y, '.', label=\"Data\")\n",
    "plt.plot(x, f(x), label=\"Ground truth\")\n",
    "plt.plot(x, model(x), label=\"Predictions\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"Current loss: %1.6f\" % loss(y, model(x)).numpy())"
   ],
   "metadata": {
    "id": "uO8upPPx9KRZ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Given a callable model, inputs, outputs, and a learning rate...\n",
    "def train(model, x, y, learning_rate):\n",
    "\n",
    "  with tf.GradientTape() as t:\n",
    "    # Trainable variables are automatically tracked by GradientTape\n",
    "    current_loss = loss(y, model(x))\n",
    "\n",
    "  # Use GradientTape to calculate the gradients with respect to W and b\n",
    "  dw, db = t.gradient(current_loss, [model.w, model.b])\n",
    "\n",
    "  # Subtract the gradient scaled by the learning rate\n",
    "  model.w.assign_sub(learning_rate * dw)\n",
    "  model.b.assign_sub(learning_rate * db)"
   ],
   "metadata": {
    "id": "-vdXFP4f9KJC"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model = MyModel()\n",
    "\n",
    "# Collect the history of W-values and b-values to plot later\n",
    "weights = []\n",
    "biases = []\n",
    "epochs = range(10)\n",
    "\n",
    "# Define a training loop\n",
    "def report(model, loss):\n",
    "  return f\"W = {model.w.numpy():1.2f}, b = {model.b.numpy():1.2f}, loss={loss:2.5f}\"\n",
    "\n",
    "\n",
    "def training_loop(model, x, y):\n",
    "\n",
    "  for epoch in epochs:\n",
    "    # Update the model with the single giant batch\n",
    "    train(model, x, y, learning_rate=0.1)\n",
    "\n",
    "    # Track this before I update\n",
    "    weights.append(model.w.numpy())\n",
    "    biases.append(model.b.numpy())\n",
    "    current_loss = loss(y, model(x))\n",
    "\n",
    "    print(f\"Epoch {epoch:2d}:\")\n",
    "    print(\"    \", report(model, current_loss))"
   ],
   "metadata": {
    "id": "AdU_Olfq9KGt"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "current_loss = loss(y, model(x))\n",
    "\n",
    "print(f\"Starting:\")\n",
    "print(\"    \", report(model, current_loss))\n",
    "\n",
    "training_loop(model, x, y)"
   ],
   "metadata": {
    "id": "5ruZJTOI9J_9"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plt.plot(epochs, weights, label='Weights', color=colors[0])\n",
    "plt.plot(epochs, [TRUE_W] * len(epochs), '--',\n",
    "         label = \"True weight\", color=colors[0])\n",
    "\n",
    "plt.plot(epochs, biases, label='bias', color=colors[1])\n",
    "plt.plot(epochs, [TRUE_B] * len(epochs), \"--\",\n",
    "         label=\"True bias\", color=colors[1])\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "zWggL47g9U2P"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plt.plot(x, y, '.', label=\"Data\")\n",
    "plt.plot(x, f(x), label=\"Ground truth\")\n",
    "plt.plot(x, model(x), label=\"Predictions\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"Current loss: %1.6f\" % loss(model(x), y).numpy())"
   ],
   "metadata": {
    "id": "bdic4k1e9XMA"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class MyModelKeras(tf.keras.Model):\n",
    "  def __init__(self, **kwargs):\n",
    "    super().__init__(**kwargs)\n",
    "    # Initialize the weights to `5.0` and the bias to `0.0`\n",
    "    # In practice, these should be randomly initialized\n",
    "    self.w = tf.Variable(5.0)\n",
    "    self.b = tf.Variable(0.0)\n",
    "\n",
    "  def call(self, x):\n",
    "    return self.w * x + self.b\n",
    "\n",
    "keras_model = MyModelKeras()\n",
    "\n",
    "# Reuse the training loop with a Keras model\n",
    "training_loop(keras_model, x, y)\n",
    "\n",
    "# You can also save a checkpoint using Keras's built-in support\n",
    "keras_model.save_weights(\"my_checkpoint\")"
   ],
   "metadata": {
    "id": "SjV6IuMo9YEu"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "keras_model = MyModelKeras()\n",
    "\n",
    "# compile sets the training parameters\n",
    "keras_model.compile(\n",
    "    # By default, fit() uses tf.function().  You can\n",
    "    # turn that off for debugging, but it is on now.\n",
    "    run_eagerly=False,\n",
    "\n",
    "    # Using a built-in optimizer, configuring as an object\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.1),\n",
    "\n",
    "    # Keras comes with built-in MSE error\n",
    "    # However, you could use the loss function\n",
    "    # defined above\n",
    "    loss=tf.keras.losses.mean_squared_error,\n",
    ")"
   ],
   "metadata": {
    "id": "NHZ_Q3Ko9YB7"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(x.shape[0])\n",
    "keras_model.fit(x, y, epochs=10, batch_size=1000)"
   ],
   "metadata": {
    "id": "kWoZPb4S9esv"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# How to train an artificial neural network with TensorFlow"
   ],
   "metadata": {
    "id": "vz5kuzyisoy0"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data pre-processing"
   ],
   "metadata": {
    "id": "zJhRERq2ssW8"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!git clone https://github.com/mlnuggets/tensorflow.git\n",
    "!mv tensorflow/train.csv train.csv "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"train.csv\")"
   ],
   "metadata": {
    "id": "EFeFV6rfspo-"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df.head()"
   ],
   "metadata": {
    "id": "hVez20dQWHS_"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df.info()"
   ],
   "metadata": {
    "id": "tUDRPDC7W8sy"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df.head()"
   ],
   "metadata": {
    "id": "9tkGimrSauQr"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df['Arrival Delay in Minutes'] = df['Arrival Delay in Minutes'].mean()"
   ],
   "metadata": {
    "id": "QB8NIRGJj4_F"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "df = df.assign(satisfaction = labelencoder.fit_transform(df[\"satisfaction\"]))"
   ],
   "metadata": {
    "id": "8xiV8HC1aV29"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "categories = df.select_dtypes(include=['object']).columns.tolist()"
   ],
   "metadata": {
    "id": "mhyzHZIXWhSl"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "categories"
   ],
   "metadata": {
    "id": "7DAgYsnvWhPd"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data transformation"
   ],
   "metadata": {
    "id": "cFOt9srdsypB"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer"
   ],
   "metadata": {
    "id": "exV4RTs4j8Sg"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X = df.drop([\"Unnamed: 0\", \"id\",\"satisfaction\"], axis=1)\n",
    "y = df[\"satisfaction\"]\n",
    "random_state = 13\n",
    "test_size = 0.3\n",
    "transformer = ColumnTransformer(transformers=[('cat', OneHotEncoder(handle_unknown='ignore', drop=\"first\"), categories)],remainder=MinMaxScaler())\n",
    "X = transformer.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size,random_state=random_state)"
   ],
   "metadata": {
    "id": "WpYdQrzcszp2"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "X_train"
   ],
   "metadata": {
    "id": "E97LUhA8a78-"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "X_train.shape[1]"
   ],
   "metadata": {
    "id": "iode19hye4Ue"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build the artificial neural network"
   ],
   "metadata": {
    "id": "3zDRLtLZs0VG"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Input\n",
    "import tensorflow as tf"
   ],
   "metadata": {
    "id": "W9ZG-Vs8s2kx"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model = Sequential(\n",
    "    [\n",
    "        Input(shape=(X_train.shape[1],)),\n",
    "        Dense(64, activation=\"relu\",  kernel_initializer=\"glorot_uniform\",name=\"layer1\"),\n",
    "        Dense(32, activation=\"relu\", kernel_initializer=\"glorot_uniform\", name=\"layer2\"),\n",
    "        Dense(1, activation=\"sigmoid\", name=\"layer3\"),\n",
    "    ]\n",
    ")"
   ],
   "metadata": {
    "id": "mHZmvEXNdAx8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ],
   "metadata": {
    "id": "k4kZurd1dAkb"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "history = model.fit(X_train, y_train, validation_data =(X_test, y_test), batch_size = 32, epochs = 10)"
   ],
   "metadata": {
    "id": "IwYHxv05fHeR"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "history"
   ],
   "metadata": {
    "id": "v7W68mwxwhXz"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualize model performance"
   ],
   "metadata": {
    "id": "dP02twd5Rwoe"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "metrics_df = pd.DataFrame(history.history)\n",
    "metrics_df[[\"loss\",\"val_loss\"]].plot();\n",
    "metrics_df[[\"accuracy\",\"val_accuracy\"]].plot();"
   ],
   "metadata": {
    "id": "ZSKqKYZGRnar"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Add Dropout Regularization to fight over-fitting"
   ],
   "metadata": {
    "id": "Opm-GKXatDSY"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "from tensorflow.keras.layers import Dropout\n",
    "model = Sequential(\n",
    "    [\n",
    "        Input(shape=(X_train.shape[1],)),\n",
    "        Dense(64, activation=\"relu\",  kernel_initializer=\"glorot_uniform\",name=\"layer1\"),\n",
    "        BatchNormalization(),\n",
    "        Dropout(rate=0.1),\n",
    "        Dense(32, activation=\"relu\", kernel_initializer=\"glorot_uniform\", name=\"layer2\"),\n",
    "        Dense(1, activation=\"sigmoid\", name=\"layer3\"),\n",
    "    ])\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = model.fit(X_train, y_train, validation_data =(X_test, y_test), batch_size = 32, epochs = 10)"
   ],
   "metadata": {
    "id": "47eUvyywtFQw"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# How to accelerate training with Batch normalization"
   ],
   "metadata": {
    "id": "FvQ6Bbswx1tj"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model = Sequential(\n",
    "    [\n",
    "        Input(shape=(X_train.shape[1],)),\n",
    "        Dense(64, activation=\"relu\",  kernel_initializer=\"glorot_uniform\",name=\"layer1\"),\n",
    "        BatchNormalization(),\n",
    "        Dense(32, activation=\"relu\", kernel_initializer=\"glorot_uniform\", name=\"layer2\"),\n",
    "        Dense(1, activation=\"sigmoid\", name=\"layer3\"),\n",
    "    ]\n",
    ")\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = model.fit(X_train, y_train, validation_data =(X_test, y_test), batch_size = 32, epochs = 10)"
   ],
   "metadata": {
    "id": "zyN6Qhp74A1W"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## How to stop model training at the right time with Early Stopping"
   ],
   "metadata": {
    "id": "9ZjcifG9yMMn"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "callbacks = [tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)]\n",
    "history = model.fit(X_train, y_train, validation_data =(X_test, y_test), batch_size = 32, epochs = 10,callbacks=callbacks)"
   ],
   "metadata": {
    "id": "POAqdepayLpL"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## How to save the best model with checkpoints"
   ],
   "metadata": {
    "id": "V31QUhtYyxPT"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "checkpoint_filepath = \"model_checkpoint\""
   ],
   "metadata": {
    "id": "S-SqmiO-yvx7"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "callbacks = [\n",
    "             \n",
    "             tf.keras.callbacks.EarlyStopping(monitor=\"loss\", patience=3),\n",
    "             \n",
    "             tf.keras.callbacks.ModelCheckpoint(\n",
    "             filepath=checkpoint_filepath,\n",
    "             save_weights_only=True,\n",
    "             monitor=\"val_accuracy\",\n",
    "             mode=\"max\",\n",
    "             save_best_only=True)]\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data =(X_test, y_test), batch_size = 32, epochs = 10,callbacks=callbacks)"
   ],
   "metadata": {
    "id": "LlK64jOeyuT6"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# The model weights (that are considered the best) are loaded into the model.\n",
    "model.load_weights(checkpoint_filepath)"
   ],
   "metadata": {
    "id": "a7N08_WRzsTy"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Make predictions on the test set"
   ],
   "metadata": {
    "id": "hesmoNrSkXMK"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "y_pred = model.predict(X_test)"
   ],
   "metadata": {
    "id": "mI-C15QgfHbG"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "y_pred = (y_pred > 0.5)"
   ],
   "metadata": {
    "id": "to9_zwkbfHSQ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plot the confusion matrix"
   ],
   "metadata": {
    "id": "uimkte2js7mN"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ],
   "metadata": {
    "id": "OHtVrk9ks8xJ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Make a single prediction"
   ],
   "metadata": {
    "id": "AAmSx2D6s9U4"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "test_data = np.expand_dims(X_test[0], axis=0)"
   ],
   "metadata": {
    "id": "J_x0Ff0Lkq-3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model.predict(test_data) > 0.5"
   ],
   "metadata": {
    "id": "t_NsKHjIs_uc"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## How to save and load Keras models"
   ],
   "metadata": {
    "id": "TMwF_UB0uSNU"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Save the weights\n",
    "model.save_weights('./checkpoints/my_checkpoint')"
   ],
   "metadata": {
    "id": "4XtbH8vk08mw"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model.save(\"saved_model\")"
   ],
   "metadata": {
    "id": "EllSTco_1OYO"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "new_model = tf.keras.models.load_model('saved_model')\n",
    "new_model.summary()"
   ],
   "metadata": {
    "id": "yUT4FHSP1X5o"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## How to perform K-fold cross-validation on Keras models "
   ],
   "metadata": {
    "id": "jx_8hD45tB7a"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "pip install scikeras[tensorflow]"
   ],
   "metadata": {
    "id": "DFMvDWmsmnhK"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# https://www.adriangb.com/scikeras/stable/\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ],
   "metadata": {
    "id": "Y-I2WYzRtCpC"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def make_model():\n",
    "  model = Sequential([\n",
    "        Input(shape=(X_train.shape[1],)),\n",
    "        Dense(64, activation=\"relu\",  kernel_initializer=\"glorot_uniform\",name=\"layer1\"),\n",
    "        Dense(32, activation=\"relu\", kernel_initializer=\"glorot_uniform\", name=\"layer2\"),\n",
    "        Dense(1, activation=\"sigmoid\", name=\"layer3\"), ])\n",
    "  return model"
   ],
   "metadata": {
    "id": "4sZvHHqWlaB_"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model = KerasClassifier(model=make_model, batch_size=32, optimizer=\"adam\", metrics=[\"accuracy\"],loss=\"binary_crossentropy\",validation_split=0.2, epochs=1)"
   ],
   "metadata": {
    "id": "6H6WBCa8lZ_a"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "accuracies = cross_val_score(estimator=model, X=X_train, y=y_train, cv = 10, n_jobs = -1)"
   ],
   "metadata": {
    "id": "ofpXKRAAm4Uq"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "mean = accuracies.mean()\n",
    "mean"
   ],
   "metadata": {
    "id": "6hwl-6ytm4Np"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "variance = accuracies.var()\n",
    "variance"
   ],
   "metadata": {
    "id": "34wkVUaYm4DT"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## How to tune model hyperparameters in Keras"
   ],
   "metadata": {
    "id": "IDC2_vEmtHM5"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "def make_model():\n",
    "  model = Sequential([\n",
    "        Input(shape=(X_train.shape[1],)),\n",
    "        Dense(64, activation=\"relu\",  kernel_initializer=\"glorot_uniform\",name=\"layer1\"),\n",
    "        Dropout(rate=0.1),\n",
    "        Dense(32, activation=\"relu\", kernel_initializer=\"glorot_uniform\", name=\"layer2\"),\n",
    "        Dense(1, activation=\"sigmoid\", name=\"layer3\"),])\n",
    "  return model"
   ],
   "metadata": {
    "id": "YxqZ5WhUtH9n"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model = KerasClassifier(model=make_model, metrics=[\"accuracy\"],loss=\"binary_crossentropy\",validation_split=0.2, epochs=1)"
   ],
   "metadata": {
    "id": "-nCLiEa1rvoU"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "params = {\n",
    "    \"batch_size\":[10,20,32,64],\n",
    "    \"epochs\":[2,3,4],\n",
    "    \"optimizer\":[\"adam\",\"rmsprop\"]\n",
    "}"
   ],
   "metadata": {
    "id": "lOVKxL3PrvgR"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "grid_search = GridSearchCV(estimator=model,\n",
    "                           param_grid=params,\n",
    "                           scoring=\"accuracy\",\n",
    "                           cv=2)"
   ],
   "metadata": {
    "id": "3AbMQQEOr8oY"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "grid_search = grid_search.fit(X_train,y_train)"
   ],
   "metadata": {
    "id": "WgIfVICer8bk"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "best_param = grid_search.best_params_\n",
    "best_accuracy = grid_search.best_score_"
   ],
   "metadata": {
    "id": "ZFtbBX1Yr8Yv"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "best_param"
   ],
   "metadata": {
    "id": "M83hz9w5tCOP"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "best_accuracy"
   ],
   "metadata": {
    "id": "6a5yhVRttGL7"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## How to tune the network parameters"
   ],
   "metadata": {
    "id": "X4igAaBcE3NJ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def make_clf(hidden_layer_sizes, dropout):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(X_train.shape[1],)))\n",
    "    for hidden_layer_size in hidden_layer_sizes:\n",
    "        model.add(Dense(hidden_layer_size, activation=\"relu\"))\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    return model"
   ],
   "metadata": {
    "id": "BgqUgdHEBxyc"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "my_model = KerasClassifier(\n",
    "    model=make_clf,\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    optimizer__learning_rate=0.1,\n",
    "    model__hidden_layer_sizes=(100,),\n",
    "    model__dropout=0.5,\n",
    "    verbose=False,\n",
    ")"
   ],
   "metadata": {
    "id": "aMcX4W9mDYaT"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "params = {\n",
    "    'optimizer__learning_rate': [0.05, 0.1],\n",
    "    'model__hidden_layer_sizes': [(100, ), (50, 50, )],\n",
    "    'model__dropout': [0, 0.5],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(my_model, params, scoring='accuracy', n_jobs=-1, verbose=True)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print(gs.best_score_, gs.best_params_)"
   ],
   "metadata": {
    "id": "pYHjkeegDOSc"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Where to go from here\n",
    "Follow us on [LinkedIn](https://www.linkedin.com/company/mlnuggets), [Twitter](https://twitter.com/ml_nuggets), [GitHub](https://github.com/mlnuggets) and subscribe to our [blog](https://www.machinelearningnuggets.com/#/portal) so that you don't miss a new issue."
   ],
   "metadata": {
    "id": "7DuyYpjAQt8y"
   }
  }
 ]
}