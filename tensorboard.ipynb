{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "21604f98"
   },
   "source": [
    "# Comprehensive TensorBoard Tutorial Workbook\n",
    "Click the image below to read the post online.\n",
    "\n",
    "<a target=\"_blank\" href=\"https://www.machinelearningnuggets.com/tensorboard-tutorial\n",
    "\"><img src=\"https://www.machinelearningnuggets.com/ezoimgfmt/digitalpress.fra1.cdn.digitaloceanspaces.com/mhujhsj/2022/07/logho-1.png?ezimgfmt=ng:webp/ngcb1\" alt=\"Open in ML Nuggets\"></a>"
   ],
   "id": "21604f98"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "182ede3f"
   },
   "source": [
    "#### Installing Tensorboard"
   ],
   "id": "182ede3f"
  },
  {
   "cell_type": "code",
   "source": [
    "# !pip install --upgrade pip\n",
    "# !pip install fairness_indicators --user\n",
    "# !pip install tensorboard-plugin-fairness-indicators --user"
   ],
   "metadata": {
    "id": "xXxK3TGSmdEf"
   },
   "id": "xXxK3TGSmdEf",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4bff061f"
   },
   "outputs": [],
   "source": [
    "rm -rf ./logs/ #remove previous logs"
   ],
   "id": "4bff061f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "536470dc"
   },
   "outputs": [],
   "source": [
    "#for kali\n",
    "\n",
    "#for windows\n",
    "import shutil\n",
    "try:\n",
    "    shutil.rmtree('logs')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "#for windows\n",
    "import shutil\n",
    "try:\n",
    "    shutil.rmtree('logsx')\n",
    "except:\n",
    "    pass"
   ],
   "id": "536470dc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b49a0fee"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np"
   ],
   "id": "b49a0fee"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "26f4d1d2"
   },
   "outputs": [],
   "source": [
    "log_dir = \"logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")"
   ],
   "id": "26f4d1d2"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f04b70b9"
   },
   "source": [
    "#### Iris Classification Model"
   ],
   "id": "f04b70b9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9d26f721"
   },
   "outputs": [],
   "source": [
    "#!pip install tensorboard"
   ],
   "id": "9d26f721"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2e81a57e"
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import tensorboard"
   ],
   "id": "2e81a57e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1afd2a30"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ],
   "id": "1afd2a30"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "af5ec6cc"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "#Neural network module\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense,Activation,Dropout\n",
    "import tensorflow\n",
    "from tensorflow.keras.layers import BatchNormalization \n",
    "from keras.utils import np_utils\n",
    "#LOaD DATA\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "#normalize\n",
    "X_normalized  =  normalize(X,axis = 0)\n",
    "\n",
    "'''\n",
    "70% -- train y\n",
    "30% -- test y\n",
    "'''\n",
    "total_length = len(y)\n",
    "train_length = int(0.8*total_length)\n",
    "test_length = int(0.2*total_length)\n",
    "\n",
    "X_train = X_normalized[:train_length]\n",
    "X_test = X_normalized[train_length:]\n",
    "y_train = y[:train_length]\n",
    "y_test = y[train_length:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train,num_classes=3)\n",
    "\n",
    "y_test = np_utils.to_categorical(y_test,num_classes=3)\n",
    "\n",
    "#Define the model\n",
    "model = Sequential()\n",
    "model.add(Dense(1000,input_dim = 4,activation = 'relu'))\n",
    "model.add(Dense(500,activation = 'relu'))\n",
    "model.add(Dense(300,activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(3,activation = 'sigmoid'))\n",
    "model.compile(loss = 'categorical_crossentropy',optimizer = 'adam',metrics = ['accuracy'])\n",
    "model.summary()"
   ],
   "id": "af5ec6cc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "acc06756"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import tensorflow as tf\n",
    "#LOaD DATA\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "#normalize\n",
    "X  =  normalize(X,axis = 0)\n",
    "\n",
    "\n",
    "#Neural network module\n",
    "from keras.models import Sequential \n",
    "import keras\n",
    "from keras.layers import Dense,Activation,Dropout\n",
    "import tensorflow\n",
    "from tensorflow.keras.layers import BatchNormalization \n",
    "from keras.utils import np_utils\n",
    "import os\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Load the iris dataset\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "# Create training and test split\n",
    "\n",
    "'''\n",
    "70% -- train y\n",
    "30% -- test y\n",
    "'''\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "X_train1, X_test1, y_train1, y_test1 = X_train, X_test, y_train, y_test\n",
    "# Create categorical labels\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    # Create the model\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(Dense(512, activation='relu', input_shape=(4,)))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "    return model\n",
    "create_model()"
   ],
   "id": "acc06756"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a026dcb8"
   },
   "outputs": [],
   "source": [
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "def train_model():\n",
    "    '''\n",
    "    utility function for training the model\n",
    "    '''\n",
    "    \n",
    "    model = create_model()\n",
    "    \n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "    model.fit(x=X_train, \n",
    "            y=y_train, \n",
    "            epochs=5, \n",
    "            validation_data=(X_test, y_test), callbacks = tensorboard_callback)\n",
    "    #\n",
    "    # Get the accuracy of test data set\n",
    "    #\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "    #\n",
    "    # Print the test accuracy\n",
    "    #\n",
    "    print('Test Accuracy: ', test_acc, '\\nTest Loss: ', test_loss)"
   ],
   "id": "a026dcb8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9fbd9d79"
   },
   "outputs": [],
   "source": [
    "tf.debugging.experimental.enable_dump_debug_info(\n",
    "    \"/tmp/tfdbg2_logdir\",\n",
    "    tensor_debug_mode=\"FULL_HEALTH\",\n",
    "    circular_buffer_size=-1)\n",
    "#train the model\n",
    "train_model()"
   ],
   "id": "9fbd9d79"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "08231a24"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard"
   ],
   "id": "08231a24"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "94ef078f"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs"
   ],
   "id": "94ef078f"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "65ea96bf"
   },
   "source": [
    "##### Scalars"
   ],
   "id": "65ea96bf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "26538d09"
   },
   "outputs": [],
   "source": [
    "%reload_ext tensorboard"
   ],
   "id": "26538d09"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1e0780d3"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "logdir = \"logs/scalars/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "file_writer = tf.summary.create_file_writer(logdir + \"/metrics\")\n",
    "file_writer.set_as_default()\n",
    "\n",
    "\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir, histogram_freq=1)\n",
    "\n",
    "def train_model():\n",
    "    '''\n",
    "    utility function for training the model\n",
    "    '''\n",
    "    \n",
    "    model = create_model()\n",
    "\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "    model.fit(x=X_train, \n",
    "            y=y_train, \n",
    "            epochs=5, \n",
    "            validation_data=(X_test, y_test), callbacks = [tensorboard_callback])\n",
    "    #\n",
    "    # Get the accuracy of test data set\n",
    "    #\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "    #\n",
    "    # Print the test accuracy\n",
    "    #\n",
    "    print('Test Accuracy: ', test_acc, '\\nTest Loss: ', test_loss)\n",
    "train_model()"
   ],
   "id": "1e0780d3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a2c5eac4"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/scalars"
   ],
   "id": "a2c5eac4"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "604788c7"
   },
   "source": [
    "##### Custom scalars"
   ],
   "id": "604788c7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f37b5852"
   },
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    \"\"\"\n",
    "    Returns a custom learning rate that decreases as epochs progress.\n",
    "    \"\"\"\n",
    "    learning_rate = 0.2\n",
    "    if epoch > 10:\n",
    "        learning_rate = 0.02\n",
    "    if epoch > 20:\n",
    "        learning_rate = 0.01\n",
    "    if epoch > 50:\n",
    "        learning_rate = 0.005\n",
    "\n",
    "    tf.summary.scalar('learning rate', data=learning_rate, step=epoch)\n",
    "    return learning_rate\n",
    "\n",
    "lr_callback = keras.callbacks.LearningRateScheduler(lr_schedule)\n",
    "\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "def train_model(epochs = 20):\n",
    "    '''\n",
    "    utility function for training the model\n",
    "    '''\n",
    "    \n",
    "    model = create_model()\n",
    "\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "    model.fit(x=X_train, \n",
    "            y=y_train, \n",
    "            epochs=epochs, \n",
    "            validation_data=(X_test, y_test), callbacks = [tensorboard_callback, lr_callback])\n",
    "    #\n",
    "    # Get the accuracy of test data set\n",
    "    #\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "    #\n",
    "    # Print the test accuracy\n",
    "    #\n",
    "    print('Test Accuracy: ', test_acc, '\\nTest Loss: ', test_loss)"
   ],
   "id": "f37b5852"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2c02ea4b"
   },
   "outputs": [],
   "source": [
    " train_model(4)"
   ],
   "id": "2c02ea4b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ab05885",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/scalars"
   ],
   "id": "8ab05885"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d6eccc90"
   },
   "source": [
    "##### Images"
   ],
   "id": "d6eccc90"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d48c34c1"
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import itertools\n",
    "import datetime\n",
    "import io\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "import shutil\n",
    "\n",
    "try:\n",
    "    shutil.rmtree('logsx')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "# Names of the integer classes\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
    "    'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "# Reshape the image for the Summary API.\n",
    "img = np.reshape(train_images[100], (-1, 28, 28, 1))\n",
    "\n",
    "# Sets up a timestamped log/images directory.\n",
    "logdir = \"logsx/images/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# Creates a file writer for the log directory.\n",
    "file_writer = tf.summary.create_file_writer(logdir)\n",
    "\n",
    "# Using the file writer, log the reshaped image\n",
    "with file_writer.as_default():\n",
    "    tf.summary.image(\"Image data\", img, step=0)"
   ],
   "id": "d48c34c1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2c156ba7"
   },
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "\n",
    "%tensorboard --logdir logsx/images"
   ],
   "id": "2c156ba7"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "61c5dd00"
   },
   "source": [
    "##### Plot multiple images"
   ],
   "id": "61c5dd00"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aa84d789"
   },
   "outputs": [],
   "source": [
    "with file_writer.as_default():\n",
    "    # Don't forget to reshape.\n",
    "    images = np.reshape(train_images[50:53], (-1, 28, 28, 1))\n",
    "    tf.summary.image(\"Plotting multiple images\", images, max_outputs=3, step=0)\n",
    "\n",
    "%tensorboard --logdir logsx/images"
   ],
   "id": "aa84d789"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cc93a87d"
   },
   "source": [
    "##### Fairness Indicators"
   ],
   "id": "cc93a87d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "115015e1"
   },
   "outputs": [],
   "source": [
    "rm -rf ./logs/"
   ],
   "id": "115015e1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b5506296"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ],
   "id": "b5506296"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "14edd4e7"
   },
   "outputs": [],
   "source": [
    "'''Packages'''\n",
    "\n",
    "from tensorboard_plugin_fairness_indicators import summary_v2\n",
    "import tensorflow.compat.v1 as tff\n",
    "import tempfile\n",
    "import tensorflow as tf\n",
    "import os\n"
   ],
   "id": "14edd4e7"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63c2fff2"
   },
   "source": [
    "#### Displaying Data"
   ],
   "id": "63c2fff2"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a3069cc0"
   },
   "source": [
    "##### Confusion Matrix"
   ],
   "id": "a3069cc0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8361897e"
   },
   "outputs": [],
   "source": [
    "#!rm -rf logs"
   ],
   "id": "8361897e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "71da070c"
   },
   "outputs": [],
   "source": [
    "#Importing Dataset\n",
    "# downloading the dataset\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "# all the classes\n",
    "class_names = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
    "\n",
    "#train model\n",
    "model = keras.models.Sequential([\n",
    "   keras.layers.Flatten(input_shape=(28, 28)),\n",
    "   keras.layers.Dense(512, activation='relu'),\n",
    "   keras.layers.Dense(256, activation='relu'),\n",
    "   keras.layers.Dense(128, activation='relu'),\n",
    "   keras.layers.Dense(64, activation='relu'),\n",
    "   keras.layers.Dense(32, activation='relu'),\n",
    "   keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ],
   "id": "71da070c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f940f0af"
   },
   "outputs": [],
   "source": [
    "# Clearing out prior logging data.\n",
    "!rm -rf logs/image\n",
    "def plot_to_image(figure):\n",
    "    \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "      returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
    "    # Save the plot to a PNG in memory.\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    # Closing the figure prevents it from being displayed directly inside\n",
    "    # the notebook.\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    # Convert PNG buffer to TF image\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    # Add the batch dimension\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    return image\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, class_names):\n",
    "    figure = plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion Matrix of the Results\")\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=90)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "\n",
    "    labels = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "    threshold = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        color = \"white\" if cm[i, j] > threshold else \"black\"\n",
    "        plt.text(j, i, labels[i, j], horizontalalignment=\"center\", color=color)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Real Class')\n",
    "    plt.xlabel('Predicted Class')\n",
    "    return figure\n",
    "\n",
    "logdir = \"logs/image/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# Defining the basic TensorBoard callback.\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "file_writer_cm = tf.summary.create_file_writer(logdir + '/cm')\n",
    "\n",
    "\n",
    "def log_confusion_matrix(epoch, logs):\n",
    "    # Using the model to predict the values from the validation dataset.\n",
    "    test_pred_raw = model.predict(test_images)\n",
    "    test_pred = np.argmax(test_pred_raw, axis=1)\n",
    "\n",
    "    # Calculating the confusion matrix.\n",
    "    cm = sklearn.metrics.confusion_matrix(test_labels, test_pred)\n",
    "    figure = plot_confusion_matrix(cm, class_names=class_names)\n",
    "    cm_image = plot_to_image(figure)\n",
    "\n",
    "    with file_writer_cm.as_default():\n",
    "        tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)\n",
    "\n",
    "# Defining the per-epoch callback.\n",
    "cm_callback = keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)"
   ],
   "id": "f940f0af"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bb561843",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Training the classifier.\n",
    "model.fit(\n",
    "   train_images,\n",
    "   train_labels,\n",
    "   epochs=1,\n",
    "   verbose=0,\n",
    "   callbacks=[tensorboard_callback, cm_callback],\n",
    "   validation_data=(test_images, test_labels),\n",
    ")"
   ],
   "id": "bb561843"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "61df4a11"
   },
   "outputs": [],
   "source": [
    "# Starting TensorBoard.\n",
    "%tensorboard --logdir logs/image"
   ],
   "id": "61df4a11"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "459ffd06"
   },
   "source": [
    "##### Text Data"
   ],
   "id": "459ffd06"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9decda17"
   },
   "outputs": [],
   "source": [
    "#define text to log\n",
    "your_text = \"This is some text in TensorBoard!\"\n",
    "# Remove prior log data.\n",
    "!rm -rf logs\n",
    "\n",
    "# Sets up a timestamped log directory.\n",
    "logdir = \"logs/text_basics/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "#log the writer to the logs directory.\n",
    "file_writer = tf.summary.create_file_writer(logdir)\n",
    "\n",
    "# Using the file writer, log the text.\n",
    "with file_writer.as_default():\n",
    "    tf.summary.text(\"TensorBoard Text\", your_text, step=0)"
   ],
   "id": "9decda17"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f2252a83"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs"
   ],
   "id": "f2252a83"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "287d1272"
   },
   "outputs": [],
   "source": [],
   "id": "287d1272"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "93d6346e"
   },
   "source": [
    "#### TensorBoard Embedding projector"
   ],
   "id": "93d6346e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "94080ad0"
   },
   "outputs": [],
   "source": [
    "#delete prior logs\n",
    "!rm -rf runs"
   ],
   "id": "94080ad0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a1edc0b2"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorboard as tb\n",
    "tf.io.gfile = tb.compat.tensorflow_stub.io.gfile\n",
    "#install pytorch\n",
    "#!pip install torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "vectors = np.array([[0,0,1], [0,1,0], [1,0,0], [1,1,1], [1,0,1]])\n",
    "metadata = ['001', '010', '100', '111', '101']  # labels\n",
    "writer = SummaryWriter()\n",
    "writer.add_embedding(vectors, metadata)\n",
    "\n",
    "writer.close()\n",
    "\n",
    "%tensorboard --logdir=runs"
   ],
   "id": "a1edc0b2"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "499419e0"
   },
   "source": [
    "#### Training Examples"
   ],
   "id": "499419e0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "64583d6a"
   },
   "outputs": [],
   "source": [
    "#clear previous logs\n",
    "#!rm -rf logs/train_data\n",
    "# Download the mnist data. The data is already divided into train and test.\n",
    "# The labels are integers representing classes.\n",
    "handwriting_mnist = keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = \\\n",
    "    handwriting_mnist.load_data()\n",
    "\n",
    "logdir = \"logs/train_data/\"\n",
    "\n",
    "file_writer = tf.summary.create_file_writer(logdir)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "with file_writer.as_default():\n",
    "    images = np.reshape(train_images[50:53], (-1, 28, 28, 1))\n",
    "    tf.summary.image(\"3 Digits\", images, max_outputs=3, step=0)"
   ],
   "id": "64583d6a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dea426fb"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/train_data"
   ],
   "id": "dea426fb"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ae056155"
   },
   "source": [
    "##### Images"
   ],
   "id": "ae056155"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "01fc24b6"
   },
   "outputs": [],
   "source": [
    "# Clear out prior logging data.\n",
    "!rm -rf logs/plots\n",
    "\n",
    "logdir = \"logs/plots/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "file_writer = tf.summary.create_file_writer(logdir)\n",
    "\n",
    "\n",
    "# class names\n",
    "class_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "\n",
    "\n",
    "def plot_to_image(figure):\n",
    "    \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "      returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
    "    # Save the plot to a PNG in memory.\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    # Closing the figure prevents it from being displayed directly inside\n",
    "    # the notebook.\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    # Convert PNG buffer to TF image\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    # Add the batch dimension\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    return image\n",
    "\n",
    "def image_grid():\n",
    "    \"\"\"\n",
    "      Return a 5x5 grid of the MNIST images as a matplotlib figure.\n",
    "    \"\"\"\n",
    "    # Create a figure to contain the plot.\n",
    "    figure = plt.figure(figsize=(10,10))\n",
    "    for i in range(25):\n",
    "        # Start next subplot.\n",
    "        plt.subplot(5, 5, i + 1, title=class_names[train_labels[i]])\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "\n",
    "    return figure\n",
    "\n",
    "# Prepare the plot\n",
    "figure = image_grid()\n",
    "# Convert to image and log\n",
    "with file_writer.as_default():\n",
    "    tf.summary.image(\"Image data\", plot_to_image(figure), step=0)"
   ],
   "id": "01fc24b6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "49563a64"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/plots"
   ],
   "id": "49563a64"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cf01c40d"
   },
   "source": [
    "##### Hyperparameters"
   ],
   "id": "cf01c40d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5bab933b"
   },
   "outputs": [],
   "source": [
    "rm -rf ./logs/"
   ],
   "id": "5bab933b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eb34665d"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "#Neural network module\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense,Activation,Dropout\n",
    "import tensorflow\n",
    "from tensorflow.keras.layers import BatchNormalization \n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "#import package\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "import keras"
   ],
   "id": "eb34665d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e232d7bc"
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "# Create training and test split\n",
    "\n",
    "'''\n",
    "70% -- train y\n",
    "30% -- test y\n",
    "'''\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "# Create categorical labels\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)"
   ],
   "id": "e232d7bc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "edc731f6"
   },
   "outputs": [],
   "source": [
    "## Create hyperparameters\n",
    "HP_NUM_UNITS=hp.HParam('num_units', hp.Discrete([ 5, 10]))\n",
    "HP_DROPOUT=hp.HParam('dropout', hp.RealInterval(0.1, 0.2))\n",
    "HP_LEARNING_RATE= hp.HParam('learning_rate', hp.Discrete([0.001, 0.0005, 0.0001]))\n",
    "HP_OPTIMIZER=hp.HParam('optimizer', hp.Discrete(['adam', 'sgd', 'rmsprop']))\n",
    "METRIC_ACCURACY='accuracy'"
   ],
   "id": "edc731f6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1aed3792"
   },
   "outputs": [],
   "source": [
    "'''Set configuration log files'''\n",
    "log_dir ='logs/fit/' + datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "with tf.summary.create_file_writer(log_dir).as_default():\n",
    "    hp.hparams_config(\n",
    "    hparams=\n",
    "    [HP_NUM_UNITS, HP_DROPOUT,  HP_OPTIMIZER, HP_LEARNING_RATE],\n",
    "    metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
    "    )"
   ],
   "id": "1aed3792"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ee09ad72"
   },
   "outputs": [],
   "source": [
    "def create_model(hparams):\n",
    "    # Create the model\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(Dense(512, activation='relu', input_shape=(4,)))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    \n",
    "    #setting the optimizer and learning rate\n",
    "    optimizer = hparams[HP_OPTIMIZER]\n",
    "    learning_rate = hparams[HP_LEARNING_RATE]\n",
    "    if optimizer == \"adam\":\n",
    "        optimizer = tf.optimizers.Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == \"sgd\":\n",
    "        optimizer = tf.optimizers.SGD(learning_rate=learning_rate)\n",
    "    elif optimizer=='rmsprop':\n",
    "        optimizer = tf.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "    else:\n",
    "        raise ValueError(\"unexpected optimizer name: %r\" % (optimizer_name,))\n",
    "    \n",
    "    # Comiple the mode with the optimizer and learninf rate specified in hparams\n",
    "    model.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    #Fit the model \n",
    "    model.fit(X_train, y_train, epochs=1, callbacks=[\n",
    "        tf.keras.callbacks.TensorBoard(log_dir),  # log metrics\n",
    "        hp.KerasCallback(log_dir, hparams),# log hparams\n",
    "        \n",
    "    ]) # Run with 1 epoch to speed things up for demo purposes\n",
    "    _, accuracy = model.evaluate(X_test, y_test)\n",
    "        \n",
    "    return accuracy"
   ],
   "id": "ee09ad72"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ac6bb2e9"
   },
   "outputs": [],
   "source": [
    "def run(run_dir, hparams):\n",
    "  with tf.summary.create_file_writer(run_dir).as_default():\n",
    "    hp.hparams(hparams)  # record the values used in this trial\n",
    "    accuracy = create_model(hparams)\n",
    "    #converting to tf scalar\n",
    "    accuracy= tf.reshape(tf.convert_to_tensor(accuracy), []).numpy()\n",
    "    tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)"
   ],
   "id": "ac6bb2e9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "92407b18"
   },
   "outputs": [],
   "source": [
    "session_num = 0\n",
    "for num_units in HP_NUM_UNITS.domain.values:\n",
    "  for dropout_rate in (HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value):\n",
    "    for optimizer in HP_OPTIMIZER.domain.values:\n",
    "        for learning_rate in HP_LEARNING_RATE.domain.values:\n",
    "          hparams = {\n",
    "              HP_NUM_UNITS: num_units,\n",
    "              HP_DROPOUT: dropout_rate,\n",
    "              HP_OPTIMIZER: optimizer,\n",
    "              HP_LEARNING_RATE: learning_rate,\n",
    "          }\n",
    "          run_name = \"run-%d\" % session_num\n",
    "          print('--- Starting trial: %s' % run_name)\n",
    "          print({h.name: hparams[h] for h in hparams})\n",
    "          run('logs/hparam_tuning/' + run_name, hparams)\n",
    "          session_num += 1"
   ],
   "id": "92407b18"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e03dcd3a"
   },
   "outputs": [],
   "source": [
    "%reload_ext tensorboard"
   ],
   "id": "e03dcd3a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1e9c1f1b"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/hparam_tuning"
   ],
   "id": "1e9c1f1b"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bbb7f7e2"
   },
   "source": [
    "##### Debugger"
   ],
   "id": "bbb7f7e2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d78c19ef"
   },
   "outputs": [],
   "source": [
    "#install profile plugin\n",
    "!pip install -U tensorboard-plugin-profile"
   ],
   "id": "d78c19ef"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "39ea2e46"
   },
   "outputs": [],
   "source": [
    "rm -rf ./logs/"
   ],
   "id": "39ea2e46"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "53c4b987",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#retrain the model\n",
    "def create_model():\n",
    "    # Create the model\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(Dense(512, activation='relu', input_shape=(4,)))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "logdir = os.path.join(\"logs/debugg\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "tf.debugging.experimental.enable_dump_debug_info(\n",
    "    logdir, tensor_debug_mode=\"FULL_HEALTH\", circular_buffer_size=-1\n",
    "    )\n",
    "    \n",
    "def train_model(epochs = 20):\n",
    "    '''\n",
    "    utility function for training the model\n",
    "    '''\n",
    "    \n",
    "    model = create_model()\n",
    "\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "    \n",
    "    tf.debugging.experimental.enable_dump_debug_info(\n",
    "    \"logs/debugg\", tensor_debug_mode=\"FULL_HEALTH\", circular_buffer_size=-1\n",
    "    )\n",
    "\n",
    "    model.fit(x=X_train, \n",
    "            y=y_train, \n",
    "            epochs=epochs, \n",
    "            validation_data=(X_test, y_test), callbacks = tensorboard_callback)\n",
    "    #\n",
    "    # Get the accuracy of test data set\n",
    "    #\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "    #\n",
    "    # Print the test accuracy\n",
    "    #\n",
    "    print('Test Accuracy: ', test_acc, '\\nTest Loss: ', test_loss)\n",
    "\n",
    "train_model(2)"
   ],
   "id": "53c4b987"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7b78171d"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/debugg"
   ],
   "id": "7b78171d"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "45708c02"
   },
   "source": [
    "#### PyTorch"
   ],
   "id": "45708c02"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "437a2954"
   },
   "outputs": [],
   "source": [
    "rm -rf ./runs/"
   ],
   "id": "437a2954"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QwFA_EaKNTxg"
   },
   "outputs": [],
   "source": [
    "#install pytorch\n",
    "!pip install torch"
   ],
   "id": "QwFA_EaKNTxg"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d829abc0"
   },
   "outputs": [],
   "source": [
    "#install torch\n",
    "#pip install torch\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "#define summary writer\n",
    "writer = SummaryWriter()\n",
    "#data\n",
    "x = torch.arange(-5, 5, 0.1).view(-1, 1)\n",
    "y = -5 * x + 0.1 * torch.randn(x.size())\n",
    "#model\n",
    "model = torch.nn.Linear(1, 1)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.1)\n",
    "\n",
    "def train_model(iter):\n",
    "    for epoch in range(iter):\n",
    "        y1 = model(x)\n",
    "        loss = criterion(y1, y)\n",
    "        writer.add_scalar(\"Loss/train\", loss, epoch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "train_model(10)\n",
    "\n",
    "writer.flush()\n",
    "#close writer\n",
    "writer.close()"
   ],
   "id": "d829abc0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "742ba38b"
   },
   "outputs": [],
   "source": [
    "for n_iter in range(100):\n",
    "    writer.add_scalar('Loss/train', np.random.random(), n_iter)\n",
    "    writer.add_scalar('Loss/test', np.random.random(), n_iter)\n",
    "    writer.add_scalar('Accuracy/train', np.random.random(), n_iter)\n",
    "    writer.add_scalar('Accuracy/test', np.random.random(), n_iter)"
   ],
   "id": "742ba38b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "37f970a9"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir=runs"
   ],
   "id": "37f970a9"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b9c4e6f4"
   },
   "source": [
    "#### Keras"
   ],
   "id": "b9c4e6f4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f539bf44"
   },
   "outputs": [],
   "source": [
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs/experiment\", histogram_freq=1)\n",
    "model = create_model()\n",
    "\n",
    "model.fit(X_train, y_train, epochs=5, callbacks=[tb_callback])"
   ],
   "id": "f539bf44"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aa708441"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/experiment"
   ],
   "id": "aa708441"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "216c14c3"
   },
   "source": [
    "##### XGBoost"
   ],
   "id": "216c14c3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "28525daf"
   },
   "outputs": [],
   "source": [
    "rm -rf ./runs/"
   ],
   "id": "28525daf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O6ZqmTxF5-sw"
   },
   "outputs": [],
   "source": [
    "#install xgb boost\n",
    "!pip install xgboost==1.5.0\n",
    "!pip install tensorboardX"
   ],
   "id": "O6ZqmTxF5-sw"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a97708a4"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "#conda install -c anaconda py-xgboost\n",
    "import xgboost as xgb\n",
    "import os\n",
    "#set some xgboost attributes that miss in version 1.6.x\n",
    "new_attrs = ['grow_policy', 'max_bin', 'eval_metric', 'callbacks', 'early_stopping_rounds', 'max_cat_to_onehot', 'max_leaves', 'sampling_method']\n",
    "\n",
    "for attr in new_attrs:\n",
    "    setattr(xgb, attr, None)\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "class TensorBoardCallback(xgb.callback.TrainingCallback):\n",
    "    '''\n",
    "    Run experiments while scoring the model and saving the error to train or test folders\n",
    "    '''\n",
    "    def __init__(self, experiment: str = None, data_name: str = None):\n",
    "        self.experiment = experiment or \"logs\"\n",
    "        self.data_name = data_name or \"test\"\n",
    "        self.datetime_ = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        #save the logs to the 'run/' folder\n",
    "        self.log_dir = f\"runs/{self.experiment}/{self.datetime_}\"\n",
    "        self.train_writer = SummaryWriter(log_dir=os.path.join(self.log_dir, \"train/\"))\n",
    "        if self.data_name:\n",
    "            self.test_writer = SummaryWriter(\n",
    "                log_dir=os.path.join(self.log_dir, f\"{self.data_name}/\")\n",
    "            )\n",
    "\n",
    "    def after_iteration(\n",
    "        self, model, epoch: int, evals_log: xgb.callback.TrainingCallback.EvalsLog\n",
    "    ) -> bool:\n",
    "        if not evals_log:\n",
    "            return False\n",
    "\n",
    "        for data, metric in evals_log.items():\n",
    "            for metric_name, log in metric.items():\n",
    "                score = log[-1][0] if isinstance(log[-1], tuple) else log[-1]\n",
    "                if data == \"train\":\n",
    "                    self.train_writer.add_scalar(metric_name, score, epoch)\n",
    "                else:\n",
    "                    self.test_writer.add_scalar(metric_name, score, epoch)\n",
    "\n",
    "        return False\n",
    "\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "X, y =  fetch_openml(name=\"house_prices\", return_X_y=True)\n",
    "#subset numerical variables\n",
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "X = X.select_dtypes(include=numerics)\n",
    "#subset the data to train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train, enable_categorical = True)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test, enable_categorical = True)\n",
    "\n",
    "params = {'objective':'reg:squarederror', 'eval_metric': 'rmse'}\n",
    "\n",
    "bst = xgb.train(params, dtrain, num_boost_round=100, evals=[(dtrain, 'train'), (dtest, 'test')],\n",
    "        callbacks=[TensorBoardCallback(experiment='exp_1', data_name='test')])"
   ],
   "id": "a97708a4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2795e79b"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir runs/"
   ],
   "id": "2795e79b"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "91e5c3f8"
   },
   "source": [
    "#### Download TensorBoard data as pandas"
   ],
   "id": "91e5c3f8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cc6f1fb9"
   },
   "outputs": [],
   "source": [
    "import tensorboard as tb\n",
    "\n",
    "experiment_id = \"c1KCv3X3QvGwaXfgX1c4tg\"\n",
    "experiment = tb.data.experimental.ExperimentFromDev(experiment_id)\n",
    "df = experiment.get_scalars()\n",
    "df.head()"
   ],
   "id": "cc6f1fb9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "584b97e4"
   },
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    experiment_id = \"c1KCv3X3QvGwaXfgX1c4tg\"\n",
    "    experiment = tb.data.experimental.ExperimentFromDev(experiment_id)\n",
    "    df = experiment.get_scalars()\n",
    "\n",
    "    df_wide = experiment.get_scalars(pivot=True)\n",
    "    display(df_wide.head())\n",
    "except:\n",
    "    print(\"There is only a single tag\")\n",
    "    df_wide = experiment.get_scalars(pivot=False)\n",
    "    display(df_wide.head())"
   ],
   "id": "584b97e4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f7ce3bbf"
   },
   "outputs": [],
   "source": [
    "#path\n",
    "import pandas as pd\n",
    "csv_path = 'tensor_experiment_1.csv'\n",
    "df_wide.to_csv(csv_path, index=False)\n",
    "df_wide_roundtrip = pd.read_csv(csv_path)\n",
    "pd.testing.assert_frame_equal(df_wide_roundtrip, df_wide)"
   ],
   "id": "f7ce3bbf"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8901ac1b"
   },
   "source": [
    "##### TensorBoard.Dev"
   ],
   "id": "8901ac1b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "010dd490"
   },
   "outputs": [],
   "source": [
    "#clear previous logs\n",
    "#rm -rf ./logs/"
   ],
   "id": "010dd490"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b70ed616"
   },
   "outputs": [],
   "source": [
    "#load data\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "# Create training and test split\n",
    "\n",
    "'''\n",
    "70% -- train y\n",
    "30% -- test y\n",
    "'''\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "# Create categorical labels\n",
    "#y_train = np_utils.to_categorical(y_train)\n",
    "#y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train,num_classes=3)\n",
    "\n",
    "y_test = np_utils.to_categorical(y_test,num_classes=3)\n",
    "\n",
    "\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "def train_model(epochs = 20):\n",
    "    '''\n",
    "    utility function for training the model\n",
    "    '''\n",
    "    \n",
    "    model = create_model()\n",
    "\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "    model.fit(x=X_train, \n",
    "            y=y_train, \n",
    "            epochs=epochs, \n",
    "            validation_data=(X_test, y_test), callbacks = [tensorboard_callback])\n",
    "    #\n",
    "    # Get the accuracy of test data set\n",
    "    #\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "    #\n",
    "    # Print the test accuracy\n",
    "    #\n",
    "    print('Test Accuracy: ', test_acc, '\\nTest Loss: ', test_loss)\n",
    "    \n",
    "train_model(epochs = 5)"
   ],
   "id": "b70ed616"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "49ec6ab3"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs"
   ],
   "id": "49ec6ab3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6e29ce8d"
   },
   "outputs": [],
   "source": [
    "#run this in google colab\n",
    "#%tensorboard dev upload --logdir logs"
   ],
   "id": "6e29ce8d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3bfca145"
   },
   "outputs": [],
   "source": [
    "#for Jupyter notebook used\n",
    "!tensorboard dev upload --logdir logs"
   ],
   "id": "3bfca145"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Where to go from here\n",
    "Follow us on [LinkedIn](https://www.linkedin.com/company/mlnuggets), [Twitter](https://twitter.com/ml_nuggets), [GitHub](https://github.com/mlnuggets) and subscribe to our [blog](https://www.machinelearningnuggets.com/#/portal) so that you don't miss a new issue."
   ],
   "metadata": {
    "id": "NHsIuwpguO1q"
   },
   "id": "NHsIuwpguO1q"
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TensorBoard_Tutorial.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}